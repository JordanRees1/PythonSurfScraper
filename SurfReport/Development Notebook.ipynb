{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Surf Report \n",
    "# Given a URL get the surf report details\n",
    "import re\n",
    "import os\n",
    "import smtplib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import telepot as tele\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Current harcoded to our group. TODO make this dynamic\n",
    "token = '2023059476:AAHmKVHPT_lUz55soRzBSysEJsVZifE2fgY'\n",
    "chat_id = -736190449\n",
    "\n",
    "def get_webpage(page_url):\n",
    "    page = requests.get(page_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def count_total_stars(soup, type_):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    star_count = 0\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            # if count == 1:\n",
    "            #     date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            for li in tr.find_all('li', class_=type_):\n",
    "                star_count += 1 \n",
    "    \n",
    "    return star_count\n",
    "\n",
    "\n",
    "def get_day_stars(soup, type_):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    daily_stars = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        star_count = 0\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            for li in tr.find_all('li', class_=type_):\n",
    "                star_count += 1 \n",
    "        daily_stars.append({'Date':date, f'{type_} Star Count':star_count})\n",
    "\n",
    "    return daily_stars\n",
    "\n",
    "\n",
    "def get_period(soup):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    daily_period = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        total_period = 0\n",
    "        # for each day\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            td_count = 0\n",
    "            for td in tr.find_all('td'):\n",
    "                if td_count == 4:\n",
    "                    try:\n",
    "                        # Get just the time in period without the 's'\n",
    "                        total_period += int(td.h4.text.split('s')[0])\n",
    "                    except:\n",
    "                        'Opps'\n",
    "                td_count += 1 \n",
    "        # Return the period in seconds, divided by 8 as that is the amount of readings per day.\n",
    "        daily_period.append({'Date':date, 'Period':round(total_period/8), 'Unit':'s'})\n",
    "\n",
    "    return daily_period \n",
    "\n",
    "\n",
    "def get_size(soup):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    results = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        small_size = 0\n",
    "        big_size = 0\n",
    "        # for each day\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            td_count = 0\n",
    "            for td in tr.find_all('td'):\n",
    "                if td_count == 1:\n",
    "                    try:\n",
    "                        # Get the small wave size\n",
    "                        small_size += int(td.span.text.split('-')[0])\n",
    "                        # Remove the 'ft' from end [:-2] removes last two chars\n",
    "                        big_size += int(td.span.text.split('-')[1][:-2])\n",
    "                    except:\n",
    "                        'No waves found'\n",
    "                td_count += 1 \n",
    "        # Return the period in seconds, divided by 8 as that is the amount of readings per day.\n",
    "        results.append({'Date':date, 'Lower Wave Size':round(small_size/8,1), 'Higher Wave Size':round(big_size/8,1), 'ft/m':'ft'})\n",
    "\n",
    "    return results \n",
    "\n",
    "\n",
    "def get_wind_direction(soup):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    results = []\n",
    "    wind_types = ['success', 'warning', 'danger']\n",
    "    winds = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        strengths = []\n",
    "        directions = []\n",
    "        # for each day\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            td_count = 0\n",
    "            # Get the class for wind, as secondary swell affects the numbered position.\n",
    "            for types in wind_types:\n",
    "                for td in tr.find_all('td', class_=f'text-center last msw-js-tooltip td-square background-{types}'):\n",
    "                    try:     \n",
    "                        strength = td['title'].split(',')[0]\n",
    "                        # Switch statement for better grouping (helps with count)\n",
    "                        if strength == 'Very Light':\n",
    "                            strength = 'Light'\n",
    "                        if strength == 'Gentle':\n",
    "                            strength = 'Light'\n",
    "                        if strength == 'Fresh':\n",
    "                            strength = 'Moderate'\n",
    "                        if strength == 'Gale Force':\n",
    "                            strength = 'Very Strong'\n",
    "                        strengths.append(strength)\n",
    "                        winds.append(strength)\n",
    "                        direction = re.findall(r\"[a-zA-Z]+\",td['title'].split(',')[1])[0]\n",
    "                        directions.append(direction)\n",
    "                    except:\n",
    "                        'Opps'\n",
    "                    td_count += 1 \n",
    "        try:\n",
    "            common_strength = max(set(strengths), key=strengths.count)\n",
    "            common_direction = max(set(directions), key=directions.count)\n",
    "        except:\n",
    "            'blah'\n",
    "        # Return the period in seconds, divided by 8 as that is the amount of readings per day.\n",
    "        results.append({'Date':date, 'Wind Strength':common_strength, 'Wind Direction':common_direction})\n",
    "\n",
    "    return results \n",
    "\n",
    "\n",
    "def get_swell_direction(soup):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    results = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        directions = []\n",
    "        # for each day\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "            td_count = 0\n",
    "            # Get the class for wind, as secondary swell affects the numbered position.\n",
    "            for td in tr.find_all('td'):\n",
    "                if td_count == 5:\n",
    "                    try:     \n",
    "                        direction = re.findall(r\"[a-zA-Z]+\",td['title'])\n",
    "                        directions.append(direction)\n",
    "                    except:\n",
    "                        'Opps'\n",
    "                td_count += 1 \n",
    "  \n",
    "        # Return the period in seconds, divided by 8 as that is the amount of readings per day.\n",
    "        results.append({'Date':date, 'Swell Direction':direction})\n",
    "\n",
    "    return results \n",
    "\n",
    "\n",
    "# TODO: Get tides, is not working as expected and must be worked on before use!\n",
    "def get_tides(soup):\n",
    "    tbody = soup.find_all('tbody')\n",
    "    results = []\n",
    "\n",
    "    for body in tbody:\n",
    "        count = 0\n",
    "        for tr in body.find_all('tr'):\n",
    "            # Get data from tag\n",
    "            if count == 1:\n",
    "                date = tr['data-date-anchor']\n",
    "            count += 1\n",
    "        count = 0\n",
    "        low_tide_details = []\n",
    "        high_tide_details = []\n",
    "\n",
    "        # for each day\n",
    "        for tide_table in body.find_all('table', class_='table table-sm table-striped table-inverse table-tide'):\n",
    "            tr_count = 0\n",
    "            # Break as sunset table as the same class name\n",
    "            if count > 0:\n",
    "                break\n",
    "            # For each row in the table (4 runs)\n",
    "            for tr in tide_table.find_all('tr'):\n",
    "                td_count = 0\n",
    "                for td in tr.find_all('td'):\n",
    "                    if td_count == 0:\n",
    "                        tide_type = td.text\n",
    "                    if td_count == 1:\n",
    "                        try:\n",
    "                            tide_time = td.text\n",
    "                        except:\n",
    "                            'No waves found'\n",
    "                    elif td_count == 2:\n",
    "                        try:\n",
    "                            tide_height = td.text\n",
    "                        except:\n",
    "                            'No waves found'\n",
    "                    td_count += 1 \n",
    "\n",
    "                if tr_count == 0 or tr_count == 2:\n",
    "                    high_tide_details.append({tide_type: tide_time, tide_type: tide_height})\n",
    "\n",
    "                if tr_count == 1 or tr_count == 3:\n",
    "                    low_tide_details.append({tide_type: tide_time, tide_type: tide_height})\n",
    "                \n",
    "                tr_count += 1\n",
    "            count += 1   \n",
    "        # Return the period in seconds, divided by 8 as that is the amount of readings per day.\n",
    "        results.append({'Date':date, 'Low Tides':low_tide_details, 'High Tides':high_tide_details})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Get wave energy from surf forecast\n",
    "def get_wave_energy(soup):\n",
    "    count = 0 \n",
    "    day = 1\n",
    "    date_  = date.today()\n",
    "    master = []\n",
    "    \n",
    "    for td in soup.find_all('td', class_=f'forecast-table__cell forecast-table-energy__cell'):\n",
    "        count += 1\n",
    "        \n",
    "        if count == 1:\n",
    "            wave_energy = int(td.text) \n",
    "        else:\n",
    "            wave_energy += int(td.text)\n",
    "              \n",
    "        # increment day when count is multiple of 7 \n",
    "        if count % 7 == 0:\n",
    "            if day == 1:\n",
    "                wave_energy = round(wave_energy/6)\n",
    "            else:\n",
    "                wave_energy = round(wave_energy/7)\n",
    "                \n",
    "            master.append({'Day':date_.strftime(\"%A\"), 'Date':date_.strftime(\"%d/%m\"), 'Energy':wave_energy})\n",
    "            \n",
    "            day += 1\n",
    "            date_ += timedelta(days=1)\n",
    "            \n",
    "        # Don't need the eigth day as MSW only does 7\n",
    "        if day == 8:\n",
    "            break\n",
    "        \n",
    "    return pd.DataFrame(master)\n",
    "\n",
    "\n",
    "# Generic SF parser - yet to be used but can be implimented to extract any other values\n",
    "def surf_forecast_parser(soup, tag, class_, title):\n",
    "    count = 0 \n",
    "    day = 1\n",
    "    date_  = date.today()\n",
    "    master = []\n",
    "    \n",
    "    for td in soup.find_all(tag, class_=class_):\n",
    "        count += 1\n",
    "        \n",
    "        print(td)\n",
    "        \n",
    "        master.append({'Day':date_.strftime(\"%A\"), 'Date':date_.strftime(\"%d/%m\"), title:td.text})\n",
    "        \n",
    "        # increment day when count is multiple of 7 \n",
    "        if count % 14 == 0:\n",
    "            day += 1\n",
    "            date_ += timedelta(days=1)\n",
    "            \n",
    "        # Don't need the eigth day as MSW only does 7\n",
    "        if day == 8:\n",
    "            break\n",
    "        \n",
    "    return pd.DataFrame(master)\n",
    "\n",
    "\n",
    "def format_date(df):\n",
    "    df['day']=df['Date'].str[-4:-2]\n",
    "    df['month']=df['Date'].str[-2:]\n",
    "    df['Day']=df['Date'].str[:-4]\n",
    "    df['Date']=df['day']+'/'+df['month']\n",
    "    df = df.drop(columns={'day','month'})\n",
    "    day = df['Day']\n",
    "    df = df.drop(columns={'Day'})\n",
    "    df.insert(0, 'Day', day)\n",
    "    return df\n",
    "\n",
    "\n",
    "def x(x):\n",
    "    return re.findall(r'[0-9]+', x)\n",
    "\n",
    "\n",
    "def score_report(df, threshold):\n",
    "    \n",
    "    if threshold == 'low':\n",
    "        df['Score'] = 0\n",
    "\n",
    "        df.loc[df['Avg Stars'] >= 1, 'Score'] = 2\n",
    "        df.loc[df['Avg Stars'] >= 2, 'Score'] = 3\n",
    "        df.loc[df['Avg Stars'] >= 3, 'Score'] = 5\n",
    "\n",
    "        df.loc[df['Period'] > 9, 'Score'] += 0.5\n",
    "        df.loc[df['Period'] > 11, 'Score'] += 1\n",
    "        df.loc[df['Period'] > 14, 'Score'] += 2\n",
    "\n",
    "        df.loc[df['Wind Direction'] == 'Offshore', 'Score'] += 2\n",
    "        df.loc[df['Wind Direction'] == 'Onshore', 'Score'] -= 1.5\n",
    "\n",
    "        df.loc[df['Wind Strength'] == 'Light', 'Score'] += 1.5\n",
    "        df.loc[df['Wind Strength'] == 'Strong', 'Score'] -= 0.5\n",
    "        df.loc[df['Wind Strength'] == 'Very Strong', 'Score'] -= 2\n",
    "\n",
    "        df.loc[df['Lower Wave Size'] >= 3, 'Score'] += 1\n",
    "        df.loc[df['Lower Wave Size'] >= 4, 'Score'] += 2\n",
    "        df.loc[df['Higher Wave Size'] >= 4.5, 'Score'] += 1\n",
    "        df.loc[df['Higher Wave Size'] >= 6, 'Score'] += 2\n",
    "        \n",
    "        df.loc[df['Energy'] >= 150, 'Score'] += 1\n",
    "        df.loc[df['Energy'] >= 250, 'Score'] += 2\n",
    "        df.loc[df['Energy'] < 100, 'Score'] -= 7.5\n",
    "        \n",
    "\n",
    "        df.loc[df['Score'] > 10, 'Score'] = 10\n",
    "        df.loc[df['Score'] < 0, 'Score'] = 0\n",
    "        \n",
    "    else:\n",
    "        df['Score'] = 0\n",
    "\n",
    "        df.loc[df['Avg Stars'] >= 2, 'Score'] = 2\n",
    "        df.loc[df['Avg Stars'] >= 3, 'Score'] = 3\n",
    "        df.loc[df['Avg Stars'] >= 4, 'Score'] = 6\n",
    "\n",
    "        df.loc[df['Period'] > 10, 'Score'] += 0.5\n",
    "        df.loc[df['Period'] > 14, 'Score'] += 1\n",
    "        df.loc[df['Period'] > 18, 'Score'] += 2\n",
    "\n",
    "        df.loc[df['Wind Direction'] == 'Offshore', 'Score'] += 2\n",
    "        df.loc[df['Wind Direction'] == 'Onshore', 'Score'] -= 1.5\n",
    "\n",
    "        df.loc[df['Wind Strength'] == 'Light', 'Score'] += 1\n",
    "        df.loc[df['Wind Strength'] == 'Strong', 'Score'] -= 0.5\n",
    "        df.loc[df['Wind Strength'] == 'Very Strong', 'Score'] -= 1\n",
    "\n",
    "        df.loc[df['Lower Wave Size'] > 4, 'Score'] += 1\n",
    "        df.loc[df['Lower Wave Size'] > 5, 'Score'] += 2\n",
    "        df.loc[df['Higher Wave Size'] > 5, 'Score'] += 1\n",
    "        df.loc[df['Higher Wave Size'] > 8, 'Score'] += 2\n",
    "        \n",
    "        df.loc[df['Energy'] >= 200, 'Score'] += 1\n",
    "        df.loc[df['Energy'] >= 400, 'Score'] += 2\n",
    "        df.loc[df['Energy'] < 150, 'Score'] -= 5\n",
    "        \n",
    "\n",
    "        df.loc[df['Score'] > 10, 'Score'] = 10\n",
    "        df.loc[df['Score'] < 0, 'Score'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Returns a list of elements: Break Name, Stars, Period, Wave Height, Score and Days (list)\n",
    "def summarise_report(df):\n",
    "    break_ = df['Break Location'].max()\n",
    "    if df['Avg Stars'].mean == 0:\n",
    "        avg_stars = 0\n",
    "    else:\n",
    "        avg_stars = round(df['Avg Stars'].mean())\n",
    "    avg_period = round(df['Period'].mean())\n",
    "    avg_score = round(df['Score'].mean())\n",
    "    avg_waves = round((df['Higher Wave Size'].mean() + df['Lower Wave Size'].mean())/2)\n",
    "    return [break_, avg_stars, str(avg_period)+'s',str(avg_waves)+'ft', avg_score, df['Day'].values]\n",
    "\n",
    "\n",
    "# Returns the site URL from dataframe in lake for a given break and site\n",
    "def get_break_values(df, break_name, site):\n",
    "    return df[site].loc[df['break'] == break_name].values[0]\n",
    "\n",
    "\n",
    "# initalise telegram bot\n",
    "def initalise_bot(token):\n",
    "    bot = tele.Bot(token)\n",
    "    return bot\n",
    "\n",
    "\n",
    "# send a telegram message to a chat id\n",
    "def send_msg(bot, chat_id, msg):\n",
    "    bot.sendMessage(chat_id, msg)\n",
    "    return 1\n",
    "\n",
    "\n",
    "# Format message for signal\n",
    "def format_msg(df):\n",
    "    df = df.loc[df['Score'] > 5]\n",
    "\n",
    "    msg = f\"{df['Break Location'].max()} \\n\"\n",
    "    for i in range(len(df)):\n",
    "        msg += f\"\\n{df['Day'][i]} {df['Date'][i]}\\n\\\n",
    "Size: {round((df['Higher Wave Size'][i].mean() + df['Lower Wave Size'][i].mean())/2)}ft\\n\\\n",
    "Energy: {round(df['Energy'][i].mean())}\\n\\\n",
    "{df['Wind Strength'][i]} {df['Wind Direction'][i]} Wind\\n\"    \n",
    "    return msg\n",
    "\n",
    "# TODO: Function to accept threshold and send signal message if score is above threshold\n",
    "\n",
    "\n",
    "# Gets a dataframe containing all break values stored in the lake CSV file.\n",
    "def get_break_urls():\n",
    "    account_name = 'jordanslake'\n",
    "    try: \n",
    "        account_key = os.environ['lakeKey']\n",
    "    except: \n",
    "        account_key = \"scsfWt47L0lkrL8iZHgIxJDrpJEBeZqplIP6yYnEqmFNnk4FUbyp8UfbWK9P5KktT9rbR88xeCTfnJReqDF31g\"\n",
    "\n",
    "    # Azure blob connection string for CSV \n",
    "    conn_str = f'DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key}==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str)\n",
    "\n",
    "    blob_client = blob_service_client.get_blob_client(container='surf-report', blob='breaks.csv')\n",
    "\n",
    "    try:\n",
    "        storedData = blob_client.download_blob()\n",
    "        df = pd.read_csv(StringIO(storedData.content_as_text()))\n",
    "\n",
    "        # If no blob exists create a new one - ErrorCode:BlobNotFound\n",
    "    except:\n",
    "        # create blank dataframe with columns\n",
    "        df = pd.DataFrame(columns=['break', 'msw', 'surf_forecast'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Day   Date            Break Location  Avg Stars  Lower Wave Size  \\\n",
      "0  Thursday  15/12    Tynemouth - Longsands        3.25              5.4   \n",
      "1    Friday  16/12    Tynemouth - Longsands        2.81              4.2   \n",
      "2  Saturday  17/12    Tynemouth - Longsands        1.31              3.1   \n",
      "3    Sunday  18/12    Tynemouth - Longsands        0.75              2.2   \n",
      "\n",
      "   Higher Wave Size ft/m Swell Direction  Period Unit Wind Strength  \\\n",
      "0               8.4   ft           [NNE]      11    s      Moderate   \n",
      "1               6.5   ft           [NNE]      12    s         Light   \n",
      "2               4.8   ft           [NNE]      10    s      Moderate   \n",
      "3               3.5   ft            [SE]      10    s      Moderate   \n",
      "\n",
      "  Wind Direction  Energy  Score  \n",
      "0       Offshore    1557   10.0  \n",
      "1       Offshore     650   10.0  \n",
      "2       Offshore     267    9.5  \n",
      "3       Offshore     279    5.5  \n"
     ]
    }
   ],
   "source": [
    "HC_threshold = 'low'\n",
    "HC_location = 'tynemouth'\n",
    "\n",
    "df = get_break_urls()\n",
    "\n",
    "msw_link = get_break_values(df, 'towan', 'msw')\n",
    "sf_link = get_break_values(df, 'towan', 'surf_forecast')\n",
    "\n",
    "# Create bot\n",
    "bot = initalise_bot(token)\n",
    "\n",
    "# Get MSW webpage\n",
    "soup = get_webpage(msw_link)\n",
    "\n",
    "# Get surf location from page title\n",
    "surf_break = soup.findAll('h1', class_='nomargin page-title')[0].text.split('Surf')[0]\n",
    "\n",
    "# Create dataframe from dict and join\n",
    "df = pd.DataFrame(get_day_stars(soup, 'active'))\n",
    "df['Break Location'] = surf_break\n",
    "df2 = pd.DataFrame(get_day_stars(soup, 'inactive'))\n",
    "df_temp = df.merge(df2)\n",
    "\n",
    "# Get average rating for each day (semi star = half)\n",
    "df_temp['Total Stars'] = (df_temp['inactive Star Count'] / 2) + df_temp['active Star Count']\n",
    "df_temp['Avg Stars'] = round(df_temp['Total Stars'] / 8, 2)\n",
    "\n",
    "df = pd.DataFrame(get_size(soup))\n",
    "df_temp = df_temp.merge(df)\n",
    "df = pd.DataFrame(get_swell_direction(soup))\n",
    "df_temp = df_temp.merge(df)\n",
    "df = pd.DataFrame(get_period(soup))\n",
    "df_temp = df_temp.merge(df)\n",
    "df = pd.DataFrame(get_wind_direction(soup))\n",
    "df_temp = df_temp.merge(df)\n",
    "\n",
    "\n",
    "df_temp = df_temp.drop(columns={'Total Stars', 'inactive Star Count', 'active Star Count'})\n",
    "\n",
    "output = format_date(df_temp)\n",
    "\n",
    "# Get the HTML for the corresponding surf forecast url\n",
    "sf_soup = get_webpage(sf_link)\n",
    "\n",
    "# Get the wave energy from the surf forecast page\n",
    "energy = get_wave_energy(sf_soup)\n",
    "\n",
    "output = output.merge(energy)\n",
    "\n",
    "scored = score_report(df=output, threshold=HC_threshold)\n",
    "\n",
    "print(scored[scored['Score'] > 5])\n",
    "    \n",
    "# Send message to telegram   \n",
    "message = format_msg(scored)\n",
    "send_msg(bot, chat_id, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature requests\n",
    "# Split day into morning, daytime and evening\n",
    "# Headline report or more detailed report\n",
    "# Looking at threshold for sending signal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f49206fcf84a9145e7e21228cbafa911d1ac18292303b01e865d8267a9c448f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
